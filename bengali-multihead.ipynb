{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install /kaggle/input/timm-model/timm-0.3.2-py3-none-any.whl"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2021-05-24T00:31:37.483878Z",
     "iopub.execute_input": "2021-05-24T00:31:37.484149Z",
     "iopub.status.idle": "2021-05-24T00:32:04.943217Z",
     "shell.execute_reply.started": "2021-05-24T00:31:37.48412Z",
     "shell.execute_reply": "2021-05-24T00:32:04.942302Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import pyarrow.parquet as pq"
   ],
   "metadata": {
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "execution": {
     "iopub.status.busy": "2021-05-24T00:32:41.457324Z",
     "iopub.execute_input": "2021-05-24T00:32:41.457654Z",
     "iopub.status.idle": "2021-05-24T00:32:41.462482Z",
     "shell.execute_reply.started": "2021-05-24T00:32:41.457604Z",
     "shell.execute_reply": "2021-05-24T00:32:41.461589Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "IMG_SIZE=128\n",
    "N_CHANNELS=1\n",
    "def resize(pil_image, size=128, need_progress_bar=True):\n",
    "    resized = {}\n",
    "    resize_size=128\n",
    "    if need_progress_bar:\n",
    "        image = np.array(pil_image)\n",
    "        # Convert RGB to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU) #\n",
    "        contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "        idx = 0\n",
    "        ls_xmin = []\n",
    "        ls_ymin = []\n",
    "        ls_xmax = []\n",
    "        ls_ymax = []\n",
    "        for cnt in contours:\n",
    "            idx += 1\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            ls_xmin.append(x)\n",
    "            ls_ymin.append(y)\n",
    "            ls_xmax.append(x + w)\n",
    "            ls_ymax.append(y + h)\n",
    "        xmin = min(ls_xmin)\n",
    "        ymin = min(ls_ymin)\n",
    "        xmax = max(ls_xmax)\n",
    "        ymax = max(ls_ymax)\n",
    "\n",
    "        roi = image[ymin:ymax,xmin:xmax]\n",
    "        #roi = image\n",
    "        resized = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n",
    "        #resized = resized.reshape(-1)\n",
    "    return resized"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-24T00:37:22.947106Z",
     "iopub.execute_input": "2021-05-24T00:37:22.947426Z",
     "iopub.status.idle": "2021-05-24T00:37:22.959978Z",
     "shell.execute_reply.started": "2021-05-24T00:37:22.947396Z",
     "shell.execute_reply": "2021-05-24T00:37:22.959126Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from timm.models import create_model\n",
    "import torch.autograd.profiler as profiler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "from timm.models import create_model\n",
    "import glob\n",
    "\n",
    "class MultiHeadSimpleModel(nn.Module):\n",
    "  \n",
    "  def __init__(self, input_size, backbone, pretrained=True, dropout=0.2):\n",
    "    super(MultiHeadSimpleModel, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.backbone = backbone\n",
    "    self.pretrained = pretrained\n",
    "    self.dropout=dropout\n",
    "\n",
    "    self.backbone = create_model(self.backbone, self.pretrained, num_classes=0)\n",
    "\n",
    "\n",
    "    feature_size = self.backbone.state_dict()['bn2.weight'].shape[0]\n",
    "    self.root_head = nn.Linear(feature_size, 168, bias=True)\n",
    "    self.consonant_head = nn.Linear(feature_size, 168, bias=True)\n",
    "    self.vowel_head = nn.Linear(feature_size, 168, bias=True)\n",
    "\n",
    "\n",
    "    intermid = []\n",
    "    intermid.append(nn.BatchNorm1d(feature_size))\n",
    "    intermid.append(nn.Dropout(self.dropout))\n",
    "    intermid.append(nn.Linear(feature_size, 512))\n",
    "    intermid.append(nn.BatchNorm1d(512))\n",
    "\n",
    "\n",
    "    self.intermid_unique = nn.ModuleList(intermid)\n",
    "    torch.nn.init.kaiming_normal_(self.intermid_unique[2].weight)\n",
    "    self.arc_face_unique = Arcface(512, 1295)\n",
    "\n",
    "  def multi_head(self, input, unique):\n",
    "    input = self.backbone(input)\n",
    "\n",
    "    root = self.root_head(input)\n",
    "    consonant = self.consonant_head(input)\n",
    "    vowel = self.vowel_head(input)\n",
    "\n",
    "    x = self.intermid_unique[0](input)\n",
    "    for inter in self.intermid_unique[1:]:\n",
    "      x = inter(x)\n",
    "    x = F.normalize(x, p=2, dim=1)\n",
    "    unique_p = self.arc_face_unique(x, unique)\n",
    "\n",
    "    return root, consonant, vowel, unique_p\n",
    "\n",
    "\n",
    "  def forward(self, input, unique):\n",
    "    multi_head_outputs = self.multi_head(input, unique)\n",
    "\n",
    "    return multi_head_outputs\n",
    "\n",
    "def l2_norm(input,axis=1):\n",
    "    norm = torch.norm(input,2,axis,True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "\n",
    "class Arcface(nn.Module):\n",
    "    # implementation of additive margin softmax loss in https://arxiv.org/abs/1801.05599    \n",
    "    def __init__(self, embedding_size=512, classnum=51332,  s=30., m=0.5):\n",
    "        super(Arcface, self).__init__()\n",
    "        self.classnum = classnum\n",
    "        self.weight = Parameter(torch.Tensor(embedding_size,classnum))\n",
    "        # initial kernel\n",
    "        self.weight.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
    "        self.m = m # the margin value, default is 0.5\n",
    "        self.s = s # scalar value default is 64, see normface https://arxiv.org/abs/1704.06369\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.mm = self.sin_m * m  # issue 1\n",
    "        self.threshold = math.cos(math.pi - m)\n",
    "    def forward(self, embbedings, label):\n",
    "        # weights norm\n",
    "        nB = len(embbedings)\n",
    "        kernel_norm = l2_norm(self.weight,axis=0)\n",
    "        # cos(theta+m)\n",
    "        cos_theta = torch.mm(embbedings,kernel_norm)\n",
    "#         output = torch.mm(embbedings,kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1,1) # for numerical stability\n",
    "        cos_theta_2 = torch.pow(cos_theta, 2)\n",
    "        sin_theta_2 = 1 - cos_theta_2\n",
    "        sin_theta = torch.sqrt(sin_theta_2)\n",
    "        cos_theta_m = (cos_theta * self.cos_m - sin_theta * self.sin_m)\n",
    "        # this condition controls the theta+m should in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_theta - self.threshold\n",
    "        cond_mask = cond_v <= 0\n",
    "        keep_val = (cos_theta - self.mm) # when theta not in [0,pi], use cosface instead\n",
    "        cos_theta_m[cond_mask] = keep_val[cond_mask]\n",
    "        output = cos_theta * 1.0 # a little bit hacky way to prevent in_place operation on cos_theta\n",
    "        idx_ = torch.arange(0, nB, dtype=torch.long)\n",
    "        output[idx_, label] = cos_theta_m[idx_, label]\n",
    "        output *= self.s # scale up in order to make softmax work, first introduced in normface\n",
    "        return output\n",
    "\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "  def __init__(self, unique_csv, test_folder, transforms, cache=True, test=True):\n",
    "    self.unique_csv = unique_csv\n",
    "    self.test_folder = test_folder\n",
    "    unique_df = pd.read_csv(self.unique_csv)\n",
    "\n",
    "    self.img_paths = glob.glob(test_folder + '*.jpg')\n",
    "    self.names = [os.path.splitext(os.path.split(imag_path)[1])[0] for imag_path in self.img_paths]\n",
    "    self.uniques = unique_df.grapheme.unique()\n",
    "    self.transforms = transforms\n",
    "    self.img = [None] * len(self.img_paths)\n",
    "    self.test = test\n",
    "\n",
    "    if cache:\n",
    "      self.cache_images()\n",
    "\n",
    "  def cache_images(self):\n",
    "    count = 0\n",
    "    pbar = tqdm.tqdm(range(len(self.img_paths)))\n",
    "    pbar.set_description('caching images...')\n",
    "    for i, _ in enumerate(pbar):\n",
    "        name = self.names[i]\n",
    "        img = resize(Image.open(self.img_paths[i]).convert('RGB')).astype(np.uint8)\n",
    "        self.img[i] = self.transforms(img)\n",
    "\n",
    "  def load_image(self, idx):\n",
    "      img = resize(Image.open(self.img_paths[idx]).convert('RGB')).astype(np.uint8)\n",
    "      return self.transforms(img)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      img = self.load_image(idx)\n",
    "      #img = self.img[idx]\n",
    "      root = 0\n",
    "      consonant = 0\n",
    "      vowel = 0\n",
    "      unique = 0\n",
    "      return transforms.ToTensor()(img), root, consonant, vowel, unique\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.img_paths)\n",
    "\n",
    "def postprocess(preds, num_classes, EXP = -1.2):\n",
    "    p0 = np.argmax(preds,axis=1)\n",
    "\n",
    "    s = pd.Series(p0)\n",
    "    vc = s.value_counts().sort_index() # key: grapheme, label: frq from batch preds\n",
    "    df = pd.DataFrame({'a':np.arange(num_classes),'b':np.ones(num_classes)})\n",
    "    df.b = df.a.map(vc) # key: grapheme, label: frq of all graphemes (using batch preds)\n",
    "    df.fillna(df.b.min(),inplace=True)\n",
    "    mat1 = np.diag(df.b.astype('float32')**EXP)\n",
    "\n",
    "    p0 = np.argmax(preds.dot(mat1), axis=1)\n",
    "    \n",
    "    return p0\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self,\n",
    "               dataset_path='./drive/MyDrive/datasets/car classification/train_data', \n",
    "               batch_size=1, \n",
    "               model_name='tf_efficientnet_b3_ns',\n",
    "               unique_csv='./train_labels.csv',\n",
    "               output_dir='../drive/MyDrive/ckpt/grapheme/submission.csv',\n",
    "               ckpt='../drive/MyDrive/ckpt/grapheme/20.pth',\n",
    "               multihead_ckpt='../'):\n",
    "\n",
    "        # initialize attributes\n",
    "        self.dataset_path = dataset_path\n",
    "        self.batch_size = batch_size\n",
    "        self.model_name = model_name\n",
    "        self.unique_csv = unique_csv\n",
    "        self.output_dir = output_dir\n",
    "        self.ckpt = ckpt\n",
    "        self.multihead_ckpt = multihead_ckpt\n",
    "        \n",
    "        if model_name == 'tf_efficientnet_b0_ns':\n",
    "            self.input_size = (224, 224)\n",
    "        elif model_name == 'tf_efficientnet_b2_ns':\n",
    "            self.input_size = (260, 260)\n",
    "        elif model_name == 'tf_efficientnet_b3_ns':\n",
    "            self.input_size = (300, 300)\n",
    "        elif model_name == 'tf_efficientnet_b4_ns':\n",
    "            self.input_size = (380, 380)\n",
    "        elif model_name == 'tf_efficientnet_b6_ns':\n",
    "            self.input_size = (528, 528)\n",
    "        else:\n",
    "            raise Exception('non-valid model name')\n",
    "        \n",
    "        # Compose transforms\n",
    "        transform = []\n",
    "        transform += [transforms.ToPILImage()]\n",
    "        transform += [transforms.Resize(self.input_size)]\n",
    "        self.transform = transforms.Compose(transform)\n",
    "\n",
    "       \n",
    "        self.device = torch.device('cuda')\n",
    "        self.model_multihead = MultiHeadSimpleModel(self.input_size, self.model_name, pretrained=False, dropout=0).to(self.device)\n",
    "\n",
    "\n",
    "        multihead_ckpt = torch.load(self.multihead_ckpt)\n",
    "        self.model_multihead.load_state_dict(multihead_ckpt['model_multihead_state_dict'])\n",
    "\n",
    "    def test(self):\n",
    "        output_roots = []\n",
    "        output_consonants = []\n",
    "        output_vowels = []\n",
    "        count = 0\n",
    "        self.test_dataset = BengaliDataset(self.unique_csv, self.dataset_path, self.transform, cache=True)\n",
    "        self.names = self.test_dataset.names\n",
    "        self.test_dataloader = DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=0, shuffle=False)\n",
    "\n",
    "        pbar = tqdm.tqdm(self.test_dataloader)\n",
    "        pbar.set_description('testing process')\n",
    "        self.model_multihead.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, data in enumerate(pbar):\n",
    "                inputs = data[0].to(self.device)\n",
    "                inputs = inputs.repeat(1, 3, 1, 1)\n",
    "                roots = data[1].to(self.device).long()\n",
    "                consonants = data[2].to(self.device).long()\n",
    "                vowels = data[3].to(self.device).long()\n",
    "                uniques = data[4].to(self.device).long()\n",
    "\n",
    "\n",
    "                root, consonant, vowel, unique = self.model_multihead(inputs, uniques)\n",
    "\n",
    "\n",
    "                root = postprocess(torch.nn.Softmax(1)(root).cpu().numpy(), 168, -1.2)\n",
    "                consonant = postprocess(torch.nn.Softmax(1)(consonant[:,:8]).cpu().numpy(), 8, -0.5)\n",
    "                vowel = postprocess(torch.nn.Softmax(1)(vowel[:,:11]).cpu().numpy(), 11, -1.2)\n",
    "\n",
    "\n",
    "                for index in range(inputs.shape[0]):\n",
    "\n",
    "                    output_roots.append(root[index].item())\n",
    "                    output_consonants.append(consonant[index].item())\n",
    "                    output_vowels.append(vowel[index].item())\n",
    "\n",
    "        del self.test_dataset\n",
    "        del self.test_dataloader\n",
    "\n",
    "        row_id, target = [], []\n",
    "        for iid, r, c, v in zip(self.names, output_roots, output_consonants, output_vowels):\n",
    "            row_id.append(iid + '_grapheme_root')\n",
    "            target.append(int(r))\n",
    "            row_id.append(iid + '_vowel_diacritic')\n",
    "            target.append(int(v))\n",
    "            row_id.append(iid + '_consonant_diacritic')\n",
    "            target.append(int(c))\n",
    "            count += 1\n",
    "\n",
    "        sub_fn = self.output_dir\n",
    "        sub = pd.DataFrame({'row_id': row_id, 'target': target})\n",
    "        sub.to_csv(sub_fn, index=False)\n",
    "        print(f'Done wrote to {sub_fn}')\n",
    "\n",
    "tester = Tester(dataset_path='/kaggle/input/nbr-graphemes/',\n",
    "               batch_size=8,\n",
    "               model_name='tf_efficientnet_b2_ns',\n",
    "               unique_csv='/kaggle/input/bengaliai-cv19/train.csv',\n",
    "               output_dir='./submission.csv',\n",
    "               ckpt='/kaggle/input/graphemesingle/27.pth',\n",
    "               multihead_ckpt='/kaggle/input/graphemesingle/10.pth'\n",
    "               )\n",
    "tester.test()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-24T00:37:38.924183Z",
     "iopub.execute_input": "2021-05-24T00:37:38.924499Z",
     "iopub.status.idle": "2021-05-24T00:38:21.476281Z",
     "shell.execute_reply.started": "2021-05-24T00:37:38.924467Z",
     "shell.execute_reply": "2021-05-24T00:38:21.472898Z"
    },
    "_kg_hide-output": false,
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}